{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from urllib.parse import quote_plus\n",
    "from langchain.llms import HuggingFaceHub\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to database\n",
    "- when variable contain special characters like '@' we need to URL encode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_database(user: str, password: str, host: str, port: str, database: str) -> SQLDatabase:\n",
    "  # URL-encode the password\n",
    "  password = quote_plus(password)\n",
    "  db_uri = f\"mysql+mysqlconnector://{user}:{password}@{host}:{port}/{database}\"\n",
    "  return SQLDatabase.from_uri(db_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_chain(db):\n",
    "    template = \"\"\"\n",
    "    You are a data analyst at a company. You are interacting with a user who is asking you questions about the company's database.\n",
    "    Based on the table schema below, write a SQL query that would answer the user's question. Take the conversation history into account.\n",
    "    \n",
    "    <SCHEMA>{schema}</SCHEMA>\n",
    "    \n",
    "    Conversation History: {chat_history}\n",
    "    \n",
    "    Write only the SQL query and nothing else. Do not wrap the SQL query in any other text, not even backticks.\n",
    "    \n",
    "    For example:\n",
    "    Question: which 3 artists have the most tracks?\n",
    "    SQL Query: SELECT ArtistId, COUNT(*) as track_count FROM Track GROUP BY ArtistId ORDER BY track_count DESC LIMIT 3;\n",
    "    Question: Name 10 artists\n",
    "    SQL Query: SELECT Name FROM Artist LIMIT 10;\n",
    "    \n",
    "    Your turn:\n",
    "    \n",
    "    Question: {question}\n",
    "    SQL Query:\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    \n",
    "    # llm = ChatOpenAI()\n",
    "    # llm = HuggingFaceHub(repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
    "    llm = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "    \n",
    "    def get_schema(_):\n",
    "        return db.get_table_info()\n",
    "    \n",
    "    return (\n",
    "        RunnablePassthrough.assign(schema=get_schema)\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validating and refining queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_sql_query(query: str):\n",
    "    if query.strip().lower().startswith(\"select\"):\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting Up LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(user_query: str, db: SQLDatabase, chat_history: list):\n",
    "  sql_chain = get_sql_chain(db)\n",
    "  \n",
    "  template = \"\"\"\n",
    "    You are a data analyst at a company. You are interacting with a user who is asking you questions about the company's database.\n",
    "    Based on the table schema below, question, sql query, and sql response, write a natural language response.\n",
    "    <SCHEMA>{schema}</SCHEMA>\n",
    "\n",
    "    Conversation History: {chat_history}\n",
    "    SQL Query: <SQL>{query}</SQL>\n",
    "    User question: {question}\n",
    "    SQL Response: {response}\"\"\"\n",
    "  \n",
    "  prompt = ChatPromptTemplate.from_template(template)\n",
    "  \n",
    "  # llm = ChatOpenAI(model=\"gpt-4-0125-preview\")\n",
    "  # llm = HuggingFaceHub(repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
    "  llm = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "  \n",
    "  chain = (\n",
    "    RunnablePassthrough.assign(query=sql_chain).assign(\n",
    "      schema=lambda _: db.get_table_info(),\n",
    "      response=lambda vars: db.run(vars[\"query\"]),\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "  )\n",
    "  \n",
    "  return chain.invoke({\n",
    "    \"question\": user_query,\n",
    "    \"chat_history\": chat_history,\n",
    "  })\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database credentials\n",
    "user = \"root\"\n",
    "password = \"Sarthak@14\"\n",
    "host = \"localhost\"\n",
    "port = '3306'\n",
    "name = \"clv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Connect to the database\n",
    "db = init_database(user, password, host, port, name)\n",
    "print(\"Connected to database!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello! I'm a SQL assistant. Ask me anything about your database.\n",
      "Human: how many states are there\n",
      "AI: Hello! Based on the query results, there are 4 distinct states represented in the data table. These states are Washington, Arizona, Nevada, and California.\n",
      "Human: how many rows are in the dataset\n",
      "AI: Based on the SQL response, there are 9134 rows in the dataset.\n",
      "Human: name all rows in the dataaset\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    AIMessage(content=\"Hello! I'm a SQL assistant. Ask me anything about your database.\"),\n",
    "]\n",
    "\n",
    "# Print chat history\n",
    "for message in chat_history:\n",
    "    if isinstance(message, AIMessage):\n",
    "        print(f\"AI: {message.content}\")\n",
    "    elif isinstance(message, HumanMessage):\n",
    "        print(f\"Human: {message.content}\")\n",
    "\n",
    "while True:\n",
    "\n",
    "    user_query = input(\"Type a message...\")\n",
    "    if user_query is not None and user_query.strip() != \"\":\n",
    "        chat_history.append(HumanMessage(content=user_query))\n",
    "        print(f\"Human: {user_query}\")\n",
    "\n",
    "    response = get_response(user_query, db, chat_history)\n",
    "    print(f\"AI: {response}\")\n",
    "\n",
    "    chat_history.append(AIMessage(content=response))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
